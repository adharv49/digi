import os
from flask import Flask, render_template, request, jsonify, send_file, url_for, redirect, session
from datetime import timedelta
import google.generativeai as genai
import re
from PIL import Image
from io import BytesIO
import base64
from loader import predict_image
from leffa_utils.utils import list_dir
import requests
from urllib.parse import quote  # Import the quote function for URL encoding
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.preprocessing import image
from tensorflow.keras.models import load_model
import numpy as np
from werkzeug.utils import secure_filename
import time
import http.client
import json

from dotenv import load_dotenv
load_dotenv()

config = tf.compat.v1.ConfigProto()
config.gpu_options.allow_growth = True
sess = tf.compat.v1.Session(config=config)


# App config
app = Flask(__name__)
app.config['UPLOAD_FOLDER'] = 'uploads/'
os.makedirs(app.config['UPLOAD_FOLDER'], exist_ok=True)



# Setup Gemini API key (HARDCODED - NOT RECOMMENDED)
GOOGLE_API_KEY = "AIzaSyDGQRcVAHQO9XBdymjS45Kb-4do1tCMMiw"  # Replace with your actual API Key
genai.configure(api_key=GOOGLE_API_KEY)

# Create a Gemini model instance
model = genai.GenerativeModel('gemini-1.5-flash')

# Modified Prompt (for /recommend) - more general for flexibility
prompt_recommend = """Based on the person's body type in the image, recommend 3 or 4 clothing styles for both upper and bottom wear. Provide only the clothing styles. No colors, body type, or materials. Respond with simple plain words with no styles, symbols, asterics, bullet points, numbers."""

example_dir = "./ckpts/examples"
person1_images = list_dir(f"{example_dir}/person1")
garment_images = list_dir(f"{example_dir}/garment")

# RapidAPI configuration
RAPIDAPI_KEY = "023cddea22mshb9ad4b9ca86ec5fp199288jsndc080b4c401b"
RAPIDAPI_HOST = "ebay38.p.rapidapi.com"


def generate_text_from_image(image_path, prompt):
    try:
        with open(image_path, "rb") as f:
            image_data = f.read()
        contents = [{"mime_type": "image/png", "data": image_data}, prompt]
        response = model.generate_content(contents)
        response.resolve()
        if response.text:
            return response.text
        else:
            print(f"No text generated. Response info: {response}")
            return "No text generated by the model."
    except Exception as e:
        print(f"Error generating text: {e}")
        return f"Error generating text: {e}"


@app.route('/')
def landing():
    return render_template('landing.html')


@app.route('/glass_try_on')
def glasstryon():
    return render_template('glasstryon.html')

'''@app.route('/submit_user_info', methods=['POST'])
def submit_user_info():
    if 'user' not in session:
        return redirect(url_for('login'))
    
    try:
        user_data = {
            'name': request.form.get('name'),
            'age': int(request.form.get('age')),
            'height': float(request.form.get('height')),
            'weight': float(request.form.get('weight')),
            'email': session['user']['email']
        }

        user_ref = db.collection(COLLECTION_NAME).document(user_data['email'])
        user_ref.set(user_data)
        return redirect(url_for('face_type'))
    
    except Exception as e:
        return f"Error saving user data: {str(e)}", 500

'''


@app.route('/try-on', methods=['GET', 'POST'])
def try_on():
    
    '''# Redirect to landing page if user is not signed in
    if 'profile' not in session:
        return render_template('tryon.html')'''
    
    if request.method == 'POST':
        if 'src_image' not in request.files or 'ref_image' not in request.files:
            return "Error: Please upload both source and reference images", 400

        src_image_file = request.files['src_image']
        ref_image_file = request.files['ref_image']

        # Save the uploaded files
        src_image_path = os.path.join(app.config['UPLOAD_FOLDER'], src_image_file.filename)
        ref_image_path = os.path.join(app.config['UPLOAD_FOLDER'], ref_image_file.filename)
        src_image_file.save(src_image_path)
        ref_image_file.save(ref_image_path)

        vt_ref_acceleration = request.form.get('vt_ref_acceleration') == 'True'
        vt_repaint = request.form.get('vt_repaint') == 'True'
        vt_step = int(request.form.get('vt_step'))
        vt_scale = float(request.form.get('vt_scale'))
        vt_seed = int(request.form.get('vt_seed'))
        vt_model_type = request.form.get('vt_model_type')
        vt_garment_type = request.form.get('vt_garment_type')
        try:
            generated_image = predict_image(
                src_image_path, ref_image_path, vt_ref_acceleration, vt_step, vt_scale, vt_seed, vt_model_type, vt_garment_type, vt_repaint
            )

            # Convert the image to base64
            buffered = BytesIO()
            generated_image.save(buffered, format="PNG")
            img_str = base64.b64encode(buffered.getvalue()).decode()

            #os.remove(src_image_path)
            #os.remove(ref_image_path)
            return render_template('tryon.html', generated_image=img_str, person1_images=person1_images, garment_images=garment_images)

        except Exception as e:
            os.remove(src_image_path)
            os.remove(ref_image_path)
            return f"Error processing image: {str(e)}", 500

    return render_template('tryon.html', person1_images=person1_images, garment_images=garment_images)


@app.route('/recommend', methods=['GET', 'POST'])
def recommend():
    if request.method == 'POST':
        if 'image' not in request.files:
            return jsonify({'error': 'No file part'}), 400

        file = request.files['image']

        if file.filename == '':
            return jsonify({'error': 'No file selected'}), 400

        if file:
            try:
                image_path = os.path.join("static", file.filename)
                file.save(image_path)
                recommendations_text = generate_text_from_image(image_path, prompt_recommend)
                os.remove(image_path)

                return jsonify({'recommendations': recommendations_text})

            except Exception as e:
                print(f"File processing error: {e}")
                return jsonify({'error': f'File processing error {e}'}), 500

    return render_template('recommend.html')


@app.route('/fetch_ebay_products', methods=['POST'])
def fetch_ebay_products():
    keywords = request.json.get('keywords', [])
    headers = {
        'x-rapidapi-key': RAPIDAPI_KEY,
        'x-rapidapi-host': RAPIDAPI_HOST
    }
    all_products = []
    for keyword in keywords:
        ebay_url = f"https://www.ebay.com/sch/i.html?_from=R40&_trksid=m570.l1313&_nkw={keyword}&_sacat=0"
        encoded_url = quote(ebay_url)  # URL-encode the eBay URL
        url = f"https://ebay38.p.rapidapi.com/searchByURL?url={encoded_url}"

        try:
            response = requests.get(url, headers=headers)
            response.raise_for_status()
            result = response.json()
            if isinstance(result, list):
                all_products.extend(result[:3])
            else:
                print("Result not as expected", result)

            time.sleep(5)  # Delay to avoid rate limiting

        except requests.exceptions.RequestException as e:
            print(f"Error fetching from eBay for keyword '{keyword}': {e}")
            return jsonify({'error': f'Error fetching from eBay for keyword "{keyword}": {str(e)}'}), 500  # Return error to frontend
        except Exception as e:
            print(f"Unexpected error: {e}")
            return jsonify({'error': f'Unexpected error: {str(e)}'}), 500

    return jsonify({'products': all_products})




@app.route('/uploads/<filename>')
def send_uploaded_file(filename=''):
    return send_file(os.path.join(app.config['UPLOAD_FOLDER'], filename))


# Updated face_type route in app.py
@app.route('/face_type', methods=['GET', 'POST'])
def face_type():
    if request.method == 'POST':
        if 'image' not in request.files:
            return jsonify({'error': 'No file part'}), 400

        file = request.files['image']
        if file.filename == '':
            return jsonify({'error': 'No file selected'}), 400

        if file:
            try:
                filename = secure_filename(file.filename)
                image_path = os.path.join(app.config['UPLOAD_FOLDER'], filename)
                
                # Save file permanently (for debugging)
                file.save(image_path)
                print(f"File saved at: {image_path}")  # Debug
                print(f"File type: {file.content_type}, File size: {os.path.getsize(image_path)} bytes")
                
                # Validate image before processing
                try:
                    with Image.open(image_path) as img:
                        # Convert to RGB if not already (handles PNG transparency)
                        if img.mode != 'RGB':
                            img = img.convert('RGB')
                            img.save(image_path)
                            print(f"Converted image to RGB format")
                except Exception as img_err:
                    return jsonify({'error': f'Invalid image file: {str(img_err)}'}), 400
                
                # Process image
                prediction = predict_face_shape(image_path)
                if prediction == "Error":
                    return jsonify({'error': 'Unable to analyze face shape'}), 500
                    
                eyewear_recommendations = get_eyewear_recommendations(prediction)

                return jsonify({
                    'prediction': prediction,
                    'eyewear_recommendations': eyewear_recommendations
                })

            except Exception as e:
                import traceback
                print(f"File processing error: {str(e)}")
                print(traceback.format_exc())  # Print full traceback for debugging
                return jsonify({'error': f'File processing error: {str(e)}'}), 500

    return render_template('face_type.html')

# Also update the predict_face_shape function for better error handling:
def predict_face_shape(image_path):
    # Configure GPU memory growth to prevent allocation issues
    physical_devices = tf.config.list_physical_devices('GPU')
    if physical_devices:
        try:
            tf.config.experimental.set_memory_growth(physical_devices[0], True)
        except RuntimeError as e:
            print(f"GPU configuration error: {e}")

    try:
        model_path = os.path.join(os.path.dirname(__file__), 'vgg16-face-9-bestyet.h5')
        print(f"Loading model from: {model_path}")  # Debug
        
        if not os.path.exists(model_path):
            raise FileNotFoundError(f"Model file missing at: {model_path}")
            
        # Load model and run prediction
        model = tf.keras.models.load_model(model_path)
        print(f"Attempting to open: {image_path}")
        if not os.path.exists(image_path):
            raise FileNotFoundError(f"Image file missing: {image_path}")
            
        # Enhanced image loading with error handling
        try:
            img = Image.open(image_path)
            img = img.resize((224, 224))
            img_array = np.array(img)
            
            # If image has alpha channel (RGBA), convert to RGB
            if img_array.shape[-1] == 4:
                background = Image.new('RGB', img.size, (255, 255, 255))
                background.paste(img, mask=img.split()[3])  # 3 is the alpha channel
                img = background
                img_array = np.array(img)
                
            # Ensure correct dimensions and format
            if len(img_array.shape) != 3 or img_array.shape[-1] != 3:
                img = img.convert('RGB')
                img_array = np.array(img)
                
            img_array = np.expand_dims(img_array, axis=0)
            img_array = img_array / 255.0  # Normalize
            
        except Exception as img_err:
            print(f"Image processing error: {str(img_err)}")
            return "Error"

        # Get prediction
        categories = ['Heart', 'Oblong', 'Oval', 'Round', 'Square']
        prediction = model.predict(img_array)
        return categories[np.argmax(prediction)]
    
    except Exception as e:
        print(f"Prediction error: {str(e)}")
        return "Error"


def get_eyewear_recommendations(face_shape):
    eyewear_recommendations = {
        "Round": ["square eyewear", "rectangular eyewear", "cat-eye eyewear"],
        "Square": ["round eyewear", "oval eyewear", "rimless eyewear"],
        "Oval": ["aviator eyewear", "square eyewear", "cat-eye eyewear"],
        "Heart": ["cat-eye eyewear", "browline eyewear", "round eyewear"],
        "Diamond": ["oval eyewear", "cat-eye eyewear", "rimless eyewear"],
        "Oblong": ["oversized eyewear", "square eyewear", "wayfarer eyewear"]
    }
    return eyewear_recommendations.get(face_shape, [])



if __name__ == '__main__':
    app.run(debug=True, port=5000)